---
title: "Tarea 2  Estadística Multivariada"
author: "Hairo Ulises Miranda Belmonte"
date: "07 de Febrero del 2019"
output:
  html_document:
    code_folding: hide #echo=TRUE hide code its default
    
    toc: true
    toc_float: true
    # number_sections: true
    theme: readable
    highlight: textmate 
    fig_width: 7
    fig_height: 6
    fig_caption: true
       
    
---

EJERCICIO 1
---------------
Demuestre que $\Sigma_{j=1}^{n}(x_{j}-\mu)(x_{j}-\mu)^{'}=\Sigma_{j=1}^{n}(x_{j}-\bar{x})(x_{j}-\bar{x})^{'}+n(\bar{x}-\mu)(\bar{x}-\mu)^{'}$ 

$$\Sigma_{j=1}^{n}(x_{j}-\mu)(x_{j}-\mu)^{'}=$$
Sumando y restando $\bar{x}$
$$=\Sigma_{j=1}^{n}(x_{j}-\bar{x}+\bar{x}-\mu)(x_{j}-\bar{x}+\bar{x}-\mu)^{'}$$
Acomodando términos:
$$=\Sigma_{j=1}^{n}(x_{j}-\bar{x}+\bar{x}-\mu)(x_{j}-\bar{x}+\bar{x}-\mu)^{'}$$
$$=\Sigma_{j=1}^{n}[(x_{j}-\bar{x})(\bar{x}-\mu)][(x_{j}-\bar{x})^{'}+(\bar{x}-\mu)^{'}]$$
$$=\Sigma_{j=1}^{n}[(x_{j}-\bar{x})(x_{j}-\bar{x})^{'}+(x_{j}-\bar{x})(\bar{x}-\mu)^{'}+(\bar{x}-\mu)(x_{j}-\bar{x})^{'}+(\bar{x}-\mu)(\bar{x}-\mu)^{'}]$$
En donde los términos cruzados son cero; entonces:
$$=\Sigma_{j=1}^{n}[(x_{j}-\bar{x})(x_{j}-\bar{x})^{'}+(\bar{x}-\mu)(\bar{x}-\mu)^{'}]$$
$$=\Sigma_{j=1}^{n}(x_{j}-\bar{x})(x_{j}-\bar{x})^{'}+n(\bar{x}-\mu)(\bar{x}-\mu)^{'}$$


EJERCICIO 2
---------------
Demuestre que $\Sigma=\frac{1}{2b}B$ entonces $\frac{1}{|\Sigma|^b}e^{-tr(\Sigma^{-1}B)/2} \leq \frac{1}{B}^{2b^{pb}e^-pb}$ cumple la igualdad.

Separando el problema en dos:
$$tr(\Sigma^{-1}B)=tr(2bB^{-1}B)=tr(2bI)=2b$$
$$\frac{1}{|\Sigma|^{b}}=\frac{|B^{\frac{1}{2}}\Sigma^{-1}B^{\frac{1}{2}}|}{|B|}$$
$$=\frac{|\Sigma^{-1}B|}{|B|}=\frac{|2bB^{-1}B|}{|B|}=\frac{|2bI|}{|b|}=\frac{(2b)^{p}}{|B|}$$
Entonces;
$$=\Bigg(\frac{(2b)^p}{|B|}\Bigg)^{b}e^{-2bp/2}$$
$$=\frac{(2b)^{pb}}{|B|^{b}}e^{-bp}$$

EJERCICIO 3
---------------

Vea la razón del por qué la distancia generalizada se puede ver como una elipse. Justifique el resultado para $p=2$

Sea; $0<(distancia)^2=X^{'}AX$ para $x\neq0$, donde $X^{'}AX$ es definido positivo, y $A$ es una matriz simétrica; por lo tanto, la distancia de $X$ a un punto fijo, sea el $\mu$, es: $(x-\mu)^{'}A(x-\mu)$.
Si se expresa esta distancia en la raíz cuadrada, se tiene una interpretación geométrica en base a la descomposición espectral de $A$.

Suponga $p=2$. Los puntos de $X_{'}=[X_{1},X_{2}]^{'}$ a una distancia, sea "c", satisface:
$$
 \left(\begin{array}{cc} 
       X_{1} & X_{2}
     \end{array}\right)
      \left(\begin{array}{cc} 
       a_{11} & a_{12}\\
      a_{12} & a_{22}
     \end{array}\right)
         \left(\begin{array}{cc} 
       X_{1} \\
      X_{2} 
     \end{array}\right)
     =c
$$
$$
 \left(\begin{array}{cc} 
       a_{11}X_{1}+a_{12}X_{2} & a_{12}X_{1}+a_{22}X_{2}
        \end{array}\right)
         \left(\begin{array}{cc} 
       X_{1} \\
      X_{2} 
     \end{array}\right)
     =c 
$$
$$a_{11}X_{1}^{2}+a_{12}X_{1}X_{2} +a_{12}X_{1}X_{2}+a_{22}X_{2}^{2}$$
$$a_{11}X_{1}^{2}+2a_{12}X_{1}X_{2}+a_{22}X_{2}^{2}=c^{2}$$
Sin embargo, por el teorema de la descomposición espectral:
$$A=\lambda_{1} e_{1} e_{1}^{'}+\lambda_{2} e_{2} e_{2}^{'}$$
entonces;
$$X^{'}AX=X^{'}(\lambda_{1} e_{1} e_{1}^{'}+\lambda_{2} e_{2} e_{2}^{'})X$$
$$=X^{'}\lambda_{1} e_{1} e_{1}^{'}X+X^{'}\lambda_{2} e_{2} e_{2}^{'}X$$
$$=\lambda_{1} X^{'}e_{1} e_{1}^{'}X+ \lambda_{2} X^{'}e_{2} e_{2}^{'}X$$
$$=\lambda_{1} (X^{'}e_{1})^{2} + \lambda_{2} (X^{'}e_{2})^{2} $$
de esta manera;
$$c^{2}=\lambda_{1}y_{1}^{2} + \lambda_{2}y_{2}^{2}$$

es una elipse, en  $y_{1}=x^{'}e_{1}$ y $y_{2}=x^{'}e_{2}$ porque $\lambda_{1},\lambda_{2} > 0$ cuando $X^{'}AX>0$.

donde, al despejar terminos:
$$c^2=\lambda_1(x_1^{'}e_{1})^2$$
$$c=\sqrt(\lambda_1)(x_!^{'}e_{1})$$
$$c\lambda_1^{-\frac{1}{2}}=(x_1^{'}e_{1})$$
y sabemos que   $y_{1}=x_1^{'}e_{1}=xe_1^{'}$; entonces:
$$c\lambda_1^{-\frac{1}{2}}=xe_1^{'}$$
multiplicando por la derecha $e_1$, y sabiendo que $e_1^{'}e_1=1$, entonces:
$$x_1=c\lambda_1^{-\frac{1}{2}}e_{1}$$

De la misma forma se realiza para $x_2$


Por lo tanto, formas cuadraticas, o en nuestro caso, las raíz cuadrada de la distancia generalizada es;
$$c^{2}=\frac{y^{2}_{1} }{\sqrt\lambda_{1}}+ \frac{y^{2}_{2}}{\sqrt\lambda_{2}}$$


$$x_1=c\sqrt(\lambda_1)e_1$$
y por otro lado:
$$x_2=c\sqrt(\lambda_2)e_2$$
Pero sabemos que los valores propios para $\Sigma^{-1}$ son $\frac{1}{\lambda_i}$; entonces:
$$x_1=\frac{c}{\sqrt\lambda_1}e_1$$
$$x_2=\frac{c}{\sqrt\lambda_2}e_2$$


EJERCICIO Extra en clase
---------------

Realiza el QQ-plot con las observaciones que se encuentran en la diapositiva.

```{r message=FALSE}
library("magrittr")
library("ggplot2")
library("plotly")

library("kableExtra")
# Observaciones
Obs <- c(1.43, 1.62,2.46, 2.48, 2.97, 4.03,4.47, 5.76,
           6.61, 6.68, 6.79, 7.46, 7.88, 8.92, 9.42) 
j <- 1:length(Obs)
# Probabilidad ajustada
adjProb <<- sapply(j, function(j) (j-0.5)/length(Obs))
# Función cuantil
Quantile <- qnorm(adjProb)
# Gráfico QQ-plot
qq <- as.data.frame(cbind(Obs,adjProb,Quantile)) 

qq %>%
  kable() %>%
  kable_styling()

plotqq <- qq %>% ggplot() + geom_point(aes( x=qq$Quantile,y=qq$Obs), color="black", size=2) + 
  geom_abline(intercept = 5.5, slope = 2.2, linetype = 2, colour = "Red", size=1.5) +
  labs(title = "Ejercicio extra. QQ-plot", 
       subtitle = "QQ-plot", 
       x="Quantiles",
       y="Obs.",
       caption = "Observavciones proporcionadas por la clase") +
  theme( panel.background = element_rect(fill = "gray"),
            plot.margin = margin(.3, .3, .3, .3, "cm"),
            plot.background = element_rect(
              fill = "grey90",
              colour = "black",
              size = 1
              ))

ggplotly(plotqq)


```

Prueba de normalidad basada en la rectitud del QQ-plot

```{r}

distX <- (Obs - mean(Obs))^2
distQ <- (Quantile-mean(Quantile))^2
CovXQ <- (Obs - mean(Obs))*(Quantile-mean(Quantile))
R <- as.data.frame(sum(CovXQ)/(sqrt(sum(distX))*sqrt(sum(distQ))))
colnames(R) <- c("Coeficiente de correlación de Pearson")
# H0: normalidad
options(digits=4)
R %>%  kable %>%  kable_styling()
```
para un $n=15$, los puntos críticos de la prueba son; 0.9503 en $\alpha=0.10$, 0.938 para $\alpha=0.05$, y 0.9126 para $\alpha=0.01$. Por lo tanto, no se tiene evidencia suficiente para rechazar la hipótesis nula de normalidad, a cualquier vaor mayor de $\alpha$ más grande de $0.01$.


EJERCICIO 4
---------------

En climas nórdicos, las carreteras debe ser limpiadas de la nieve rápidamente después de una tormenta. Una de las medidas de la severidad de la tormenta es x1 = duración en horas, mientras que la efectividad de la limpieza de la nieve se puede cuantificar por x2 = horas de trabajo para limpiar la nieve. En la tabla inferior se muestran los resultados de 25 incidentes en Wisconsin.



a)   Detecte cualquier posible dato atípico mediante el diagrama de dispersión de las variables originales.
```{r message=FALSE}
library("gridExtra")
library("MASS")
library("knitr")
library("kableExtra")
library("geoR")
library("AID")
library("car")
library("mvtnorm")
library("cowplot")

x1 <- c(12.5, 14.5,8,9,19.5,8,9,7,7,9,6.5,10.5,10,4.5,
        7,8.5,6.5,8,3.5,8,17.5,10.5,12,6,13)
x2 <- c(13.7,16.5,17.4,11,23.6,13.2,32.1,12.3,11.8,24.4,
  18.2,22,32.5,18.7,15.8,15.6,12,12.8,26.1,14.5,42.3,
  17.5,21.8,10.4,25.6)

Obs <- cbind(x1,x2) %>% as.data.frame

Obs %>% kable  %>% kable_styling

p95 <- Obs %>% ggplot()+aes(x=x1, y=x2) + geom_point() + 
  labs(caption="95% de confianza",
       x="Duración en horas",
       y="Horas de trabajo") + 
  stat_ellipse(aes(x=x1, y=x2),type = "norm", col="blue",
               size=1, linetype = 2, level = .95)+
  theme( panel.background = element_rect(fill = "gray"),
         plot.margin = margin(.3, .3, .3, .3, "cm"),
         plot.background = element_rect(
           fill = "grey",
           colour = "black",
           size = 1
         ))

p99 <- Obs %>% ggplot()+aes(x=x1, y=x2) + geom_point() + 
  labs(caption="99% de confianza",
       x="Duración en horas",
       y="Horas de trabajo")  +
  stat_ellipse(aes(x=x1, y=x2),type = "norm", col="blue",
               size=1, linetype = 2, level = .99)+
  theme( panel.background = element_rect(fill = "gray"),
         plot.margin = margin(.3, .3, .3, .3, "cm"),
         plot.background = element_rect(
           fill = "grey",
           colour = "black",
           size = 1
         ))

plot_grid(p95,p99) 

```


Como se puede ver en el cuadro de arriba, se realiza un gráfico de dispersión para las variables; horas de trabajo y duración en horas, en el cual, al gráficar una región de confianza al 99% (cuadro de la derecha), las observaciónes en conjunto se distribuyen como una normal bivariada; no obstante, si reducimos el nivel de confianza; i.e, al 95% de significancia, se puede observar dos datos atípicos.



b) Determine la potencia de la transformación $\lambda_{1}$ que convierte los valores de $x_{1}$ aproximadamente a normales. Construya el Q-Q plot de las observaciones transformadas.

Observaciones $x_{1}$=Duración en horas.
```{r message=FALSE}
library("gridExtra")
library("MASS")
library("knitr")
library("kableExtra")
library("geoR")
library("AID")
library("car")
library("mvtnorm")
library("cowplot")
# Valores a evaluar para el parámetro lambda
lam <- seq(-3,3,.01)
# Valores  función que max lambda
Llam <- numeric(0)
# Evaluando Lambda Función
maxval <- function(i){
  xj <- ((x^lam[i])-1)/lam[i]
  n <- length(xj)
  xmeanj <- (1/n)*sum(xj)
  Llam[i] <- (-n/2)*log((1/n)*sum(((xj-xmeanj)^2)))+
    (lam[i]-1)*sum(log(x))
}
# X1
x <- Obs$x1
i <- 1:length(lam)
L <- numeric(0)
L <-sapply(i,  maxval) %>% as.data.frame
L <- cbind(L,lam)
colnames(L) <-c("LVal","Lambda")
L %>% arrange(desc(LVal)) %>% head %>% kable %>% kable_styling
L <- L %>% arrange(desc(LVal)) 
lamHat1 <- L[1,2]
na.omit(L) %>% ggplot() + geom_line(aes(x=Lambda,y=LVal), size=1,col="black") +
  geom_vline(xintercept = L[1,2],  linetype="dashed", color = "red") +
  geom_hline(yintercept = L[1,1],  linetype="dashed", color = "red") +
  labs(x=expression(lambda),
       y=expression(gamma(lambda)))

```

En el gráfico anterior se gráficaron los posibles valores del parámetro de transformación, en los cuales, al evaluarlos en la función a máximizar, se observa que el valor máximo se encuentra cuando $\gamma(\lambda)=-30.14$ y $\lambda=0.05$.

A continuación, se realiza la transformación de los datos, propuesta por box-cox; cabe mencionar, que no  se cuenta con observaciones de $x_{1}=0$, y por lo tanto, la transformación viene dada por:
$$x^{\lambda}=\frac{x^{\lambda-1}}{\lambda}$$

Realizando QQ-plot a la transformación de los datos
```{r message=FALSE}
library("gridExtra")
library("MASS")
library("knitr")
library("kableExtra")
library("geoR")
library("AID")
library("car")
library("mvtnorm")
library("cowplot")
library("plotly")
# Tansformando Datos X1
y1 <- ((x^lamHat1)-1)/lamHat1 # ninguno es cero
j <- 1:length(y1)
adjProb <- (j-.5)/length(y1)
Quant <- qnorm(adjProb)
y1 <- y1[order(y1)] 
Base <- cbind(y1,adjProb,Quant) %>%
  as.data.frame

reg1 <- lm(y1~Quant,data=Base)
coeff1 <- coefficients(reg1)

Obsx1 <- Obs[,1][order(Obs[,1])] 
Base <- cbind(Base,Obsx1) 
regx1 <- lm(Obsx1~Quant,data=Base)
coeffx1 <- coefficients(regx1)


plotx1 <- Base %>% ggplot() + geom_point(aes( x=Quant,y=Obsx1), color="black", size=2) + 
  geom_abline(intercept = coeffx1[1], slope = coeffx1[2], linetype = 2, colour = "Red", size=1.5) +
  labs(title = "QQ-plot ", 
       subtitle = "", 
       x="Quantiles",
       y="Obs.",
       caption = "") +
  theme( panel.background = element_rect(fill = "gray"),
         plot.margin = margin(.3, .3, .3, .3, "cm"),
         plot.background = element_rect(
           fill = "grey",
           colour = "black",
           size = 1
         ))
ploty1 <- Base %>% ggplot() + geom_point(aes( x=Quant,y=y1), color="black", size=2) + 
  geom_abline(intercept = coeff1[1], slope = coeff1[2], linetype = 2, colour = "Red", size=1.5) +
  labs(title = "QQ-plot ", 
       subtitle = "Box-Cox ", 
         x="Quantiles",
       y="Obs.",
       caption = "") +
  theme( panel.background = element_rect(fill = "gray"),
         plot.margin = margin(.3, .3, .3, .3, "cm"),
         plot.background = element_rect(
           fill = "grey",
           colour = "black",
           size = 1
         ))

plot_grid(ploty1,plotx1) 

```


Como se puede observar, bajo la tranformación realizada mediante la metodología de box-cox, la serie se ajusta mejor a la linea de 45°; i.e., podemos sugerir que bajo la transformación se considera una distribución normal.


(c) Determine la potencia de la transformación que convierte los valores de $x_{2}$ aproximadamente a normales. Construya el Q-Q plot de las observaciones transformadas.

Observaciones $x_{2}$= Horas de trabajo.

```{r message=FALSE}
library("gridExtra")
library("MASS")
library("knitr")
library("kableExtra")
library("geoR")
library("AID")
library("car")
library("mvtnorm")
library("cowplot")
x <- Obs$x2
i <- 1:length(lam)
L <- numeric(0)
L <-sapply(i,  maxval) %>% as.data.frame
L <- cbind(L,lam)
colnames(L) <-c("LVal","Lambda")
L %>% arrange(desc(LVal)) %>% head %>% kable %>% kable_styling
L <- L %>% arrange(desc(LVal)) 
lamHat2 <- L[1,2]
na.omit(L) %>% ggplot() + geom_line(aes(x=Lambda,y=LVal), size=1,col="black") +
  geom_vline(xintercept = L[1,2],  linetype="dashed", color = "red") +
  geom_hline(yintercept = L[1,1],  linetype="dashed", color = "red") +
  labs(x=expression(lambda),
       y=expression(gamma(lambda))) 


```

En el gráfico anterior se observan los posibles valores del parámetro de transformación, en los cuales, al evaluarlos en la función a máximizar, se observa que el valor máximo se encuentra cuando $\gamma(\lambda)=-46.23	$ y $\lambda=-0.70$.

Ahora, realizamos la transformación antes mencionada a las observaciones $x_{2}$, horas trabajadas.

Realizando QQ-plot a la transformación de los datos

```{r message=FALSE}
library("gridExtra")
library("MASS")
library("knitr")
library("kableExtra")
library("geoR")
library("AID")
library("car")
library("mvtnorm")
library("cowplot")
library("plotly")
# Tansformando Datos X1
y2 <- ((x^lamHat2)-1)/lamHat2 # ninguno es cero
j <- 1:length(y2)
adjProb <- (j-.5)/length(y2)
Quant <- qnorm(adjProb)
y2 <- y2[order(y2)] 
Base <- cbind(y2,adjProb,Quant) %>%
  as.data.frame

reg2 <- lm(y2~Quant,data=Base)
coeff2 <- coefficients(reg2)

Obsx2 <- Obs[,1][order(Obs[,1])] 
Base <- cbind(Base,Obsx2) 
regx2 <- lm(Obsx2~Quant,data=Base)
coeffx2 <- coefficients(regx2)


plotx2 <- Base %>% ggplot() + geom_point(aes( x=Quant,y=Obsx1), color="black", size=2) + 
  geom_abline(intercept = coeffx1[1], slope = coeffx1[2], linetype = 2, colour = "Red", size=1.5) +
  labs(title = "QQ-plot ", 
       subtitle = "", 
        x="Quantiles",
       y="Obs.",
       caption = "") +
  theme( panel.background = element_rect(fill = "gray"),
         plot.margin = margin(.3, .3, .3, .3, "cm"),
         plot.background = element_rect(
           fill = "grey",
           colour = "black",
           size = 1
         ))
ploty2 <- Base %>% ggplot() + geom_point(aes( x=Quant,y=y2), color="black", size=2) + 
  geom_abline(intercept = coeff2[1], slope = coeff2[2], linetype = 2, colour = "Red", size=1.5) +
  labs(title = "QQ-plot ", 
       subtitle = "Box-Cox ", 
          x="Quantiles",
       y="Obs.",
       caption = "") +
  theme( panel.background = element_rect(fill = "gray"),
         plot.margin = margin(.3, .3, .3, .3, "cm"),
         plot.background = element_rect(
           fill = "grey",
           colour = "black",
           size = 1
         ))

plot_grid(ploty2,plotx2) 

```

Al igual que $x_{1}$, la variable $x_{2}$, horas de trabajo, bajo la transformación propuesta por boxcox, se observa que sigue una distribución normal.

(d) Determine la potencia de la transformación que convierte las 
observaciones bivariadas en aproximadamente normales.

```{r message=FALSE}
library("gridExtra")
library("MASS")
library("knitr")
library("kableExtra")
library("geoR")
library("AID")
library("car")
library("mvtnorm")
library("cowplot")
# multivariate
lambdas <- c(lamHat1,lamHat2)

LamdasMv <- powerTransform(as.matrix(Obs), start=lambdas)


LamdasMv <- LamdasMv$lambda 
LamdasMv <-LamdasMv %>% as.data.frame
colnames(LamdasMv) <- c("Parámetro de Transformación") 
LamdasMv%>%
  kable %>% kable_styling

xx1 <- ((Obs[,1]^LamdasMv[[1]][1])-1)/LamdasMv[[1]][1]
xx2 <-  ((Obs[,2]^LamdasMv[[1]][2])-1)/LamdasMv[[1]][2]

# transformando

biv <- cbind(xx1,xx2) 
biv <- biv %>% as.data.frame

elipse1 <- biv  %>% ggplot()+ geom_point(aes(x=xx1, y=xx2))+
  stat_ellipse(aes(x=xx1, y=xx2), level = 0.95) + labs(title= "Ellipse",
                                         subtitle = "Box-Cox MV",
                                         caption = "95%",
                                         x= "Duración en horas",
                                         y= "Horas trabajadas")

elipse2 <- Obs  %>% ggplot()+ geom_point(aes(x=x1, y=x2))+
  stat_ellipse(aes(x=x1, y=x2),level = 0.95) + labs(title= "Ellipse",
                                       subtitle = "No transf.",
                                       caption = "95%",
                                         x= "Duración en horas",
                                         y= "Horas trabajadas")
plot_grid(elipse1,elipse2)




```

Se utilizaron los parámetros de transformación de las series univariadas para iniciar el algoritmo; i.e., el box-cox bivariado. Asimismo, se dibuja un intervalo de confianza bivariado - elipse-, al 95% de significancia. Lo que podemos observar, en el grafíco anterior , es que bajo una transformación, el conjunto de observaciones sigue teniendo valores fuera de la región de confianza; sin embargo, la distancia -eucllidina-, entre las observaciones que salen de la región y un posible centroide, podría eser menor.

```{r}
elipse1 <- biv  %>% ggplot()+ geom_point(aes(x=xx1, y=xx2))+
  stat_ellipse(aes(x=xx1, y=xx2), level = 0.99) + labs(title= "Ellipse",
                                         subtitle = "Box-Cox MV",
                                         caption = "99%",
                                         x= "Duración en horas",
                                         y= "Horas trabajadas")

elipse2 <- Obs  %>% ggplot()+ geom_point(aes(x=x1, y=x2))+
  stat_ellipse(aes(x=x1, y=x2),level = 0.99) + labs(title= "Ellipse",
                                       subtitle = "No transf.",
                                       caption = "99%",
                                         x= "Duración en horas",
                                         y= "Horas trabajadas")
plot_grid(elipse1,elipse2)
```


Al incrementar al $99\%$ de significancia la elipse, podemos ver como bajo la transformación se distribuye normal bivariada. En conclusión, la transformación ayuda de manera adecuada para aproximar la distribución de $x_{1}$ y $x_{2}$, a una normal bivariada.


Lo anterior se realizó programando la transformación de box-cox, esto para la estimación univariado; de este modo, a continuación se presenta el mismo ejercicio del inciso (b)-(d), pero utilizando la paqueteria boxcoxnc; para los casos univariados.

Para $x_{1}$: Duración en horas
```{r}
# Utilizando Función
Obsx1 <- Obs[,1] %>% boxcoxnc
```
Podemos observar que los valores del estadístico de transformación, es de $0.07$, y en el caso de cuando se programó, erá de $0.05$, lo cual no realiza muchos cambios en nuestras conclusiones.

Para $x_{2}$: Horas trabajadas

```{r}

Obsx2 <- Obs[,2] %>% boxcoxnc
```

Para este caso, observamos que el valor del parámetro de transformación estomado es el mismo al que programamos.

Realizando la versión bivariada con los parámetros de la función boxcoxnc.

```{r}

# multivariate
lambdas2 <- c(Obsx1$lambda.hat,Obsx2$lambda.hat)

LamdasMv2 <- powerTransform(as.matrix(Obs), start=lambdas2)


LamdasMv2 <- LamdasMv2$lambda 
LamdasMv2 <-LamdasMv2 %>% as.data.frame
colnames(LamdasMv2) <- c("Parámetro de Transformación") 
LamdasMv2 %>%
  kable %>% kable_styling
```

Realizando la transformación bivariada
Nota: se utilizan los parámetros de transformación de los casos univariados para inicializar las iteraciones; esto de acuerdo a la literatura.

```{r}
xx1_2 <- ((Obs[,1]^LamdasMv2[[1]][1])-1)/LamdasMv2[[1]][1]
xx2_2 <-  ((Obs[,2]^LamdasMv2[[1]][2])-1)/LamdasMv2[[1]][2]

# transformando

biv_2 <- cbind(xx1_2,xx2_2) 
biv_2 <- biv_2 %>% as.data.frame

elipse1_2 <- biv_2  %>% ggplot()+ geom_point(aes(x=xx1_2, y=xx2_2))+
  stat_ellipse(aes(x=xx1, y=xx2), level = 0.95) + labs(title= "Ellipse",
                                         subtitle = "Box-Cox MV",
                                         caption = "95%",
                                         x= "Duración en horas",
                                         y= "Horas trabajadas")

elipse2_2 <- Obs  %>% ggplot()+ geom_point(aes(x=x1, y=x2))+
  stat_ellipse(aes(x=x1, y=x2),level = 0.95) + labs(title= "Ellipse",
                                       subtitle = "No transf.",
                                       caption = "95%",
                                         x= "Duración en horas",
                                         y= "Horas trabajadas")
plot_grid(elipse1_2,elipse2_2)


```

Como podemos observar, obtuvimos los mismos resultados utilizando la funciones boxcoxnc, que programando la función para estimar los parámetros de formas univariada, y después pasarlo a la función, que si utilizamos libreria, de box.cox multivariado.


EJERCICIO 5
---------------

Para $p$ y $n$ fijos, genérese una muestra de tamaño $N$ de una ley $T^{2}(p, n)$ de Hotelling. Para esto construya una función que tome como entradas los valores de $p$, $N$, y utilice un generador de números aleatorios gaussianos. Represénte los resultados mediante un histograma, y haga pruebas para diferentes valores de entrada

La función se encuentra a continuación. Como se sabe, si $x\sim N_{p}(\mu,\Sigma)$ y $(n-1)S\sim W_{p}(S|\Sigma)$; entonces, la distribución de la variable escalar $T^{2}=(x-\mu)^{'}S^{-1}(x-\mu)$, tiene una distribución Hotelling con $p$ y $n-1$ grados de libertad $T^{2}\sim T^{2}(p,n-1)$.
Asimismo, bajo el TLC, sabemos que $S\rightarrow \Sigma $ (converge en probabilidad); entonces, $T^2$ converge a la distancia de Mahalandas, y sabemos que esa distancia se aproxima a una $\chi^2_p$ cuando $n\rightarrow\infty $.


```{r message=FALSE}
library("gridExtra")
library("MASS")
library("knitr")
library("kableExtra")
library("geoR")
library("AID")
library("car")
library("mvtnorm")
library("cowplot")

t2 <- function(p,N){
p  <- 2
mu <- numeric(p)
Sigma <- diag(p)
x <- rmvnorm(N, mean=mu, sigma=Sigma)
n <- length(x[,1])
Xmean <- colMeans(x)  
Sigma <- var(x)
#SigmaXbar <- Sigma/n 
sigmainv <- solve(Sigma)
return(mahalanobis(x,Xmean,sigmainv))
}
```

De esta manera, utilizamos la función generamos observaciones  de una normal bivariada, con $n=1000$ , y la contrastamos contra una $\chi_p^2$.
```{r}
muestra <- t2(2,1000) 
muestra <- muestra %>% as.data.frame
colnames(muestra)<- c("x")
muestra2 <- rchisq(1000,2) %>% as.data.frame

p <- ggplot(muestra, aes(x=muestra$x)) +
  geom_histogram(aes(y = ..density..), colour="white", binwidth=density(muestra$x)$bw) +
  geom_density(fill="lightcyan4", alpha = 0.2) +
  theme(panel.background = element_rect(fill = "gray90"),
        plot.margin = margin(.3, .3, .3, .3, "cm"),
        plot.background = element_rect(
          fill = "grey90",
          colour = "black",
          size = 1
        )) + 
  labs(title=expression(T^2),
       x="",
       y="") 

#ggplotly(p)
```


```{r}
p2 <- ggplot(muestra2, aes(x=muestra2$.)) +
  geom_histogram(aes(y = ..density..), colour="white", binwidth=density(muestra2$.)$bw) +
  geom_density(fill="lightcyan4", alpha = 0.2) +
  theme(panel.background = element_rect(fill = "gray90"),
         plot.margin = margin(.3, .3, .3, .3, "cm"),
         plot.background = element_rect(
           fill = "grey90",
           colour = "black",
           size = 1
         )) + 
  labs(title=expression(chi[p]^2),
       x="",
       y="") 

plot_grid(p,p2,  labels = c('A', 'B'))  
```


Ahora realizamos lo anteriorpero con $n=20$, en el cual el TLC no tendrá efecto alguno.

```{r}
# con 20

muestrab <- t2(2,20) 
muestrab <- muestrab %>% as.data.frame
colnames(muestrab)<- c("x")
muestrab2 <- rchisq(20,2) %>% as.data.frame

pb <- ggplot(muestrab, aes(x=muestrab$x)) +
  geom_histogram(aes(y = ..density..), colour="white", binwidth=density(muestrab$x)$bw) +
  geom_density(fill="lightcyan4", alpha = 0.2) +
  theme(panel.background = element_rect(fill = "gray90"),
        plot.margin = margin(.3, .3, .3, .3, "cm"),
        plot.background = element_rect(
          fill = "grey90",
          colour = "black",
          size = 1
        )) + 
  labs(title=expression(T^2),
       x="",
       y="") 

#ggplotly(p)


pb2 <- ggplot(muestrab2, aes(x=muestrab2$.)) +
  geom_histogram(aes(y = ..density..), colour="white", binwidth=density(muestrab2$.)$bw) +
  geom_density(fill="lightcyan4", alpha = 0.2) +
  theme(panel.background = element_rect(fill = "gray90"),
        plot.margin = margin(.3, .3, .3, .3, "cm"),
        plot.background = element_rect(
          fill = "grey90",
          colour = "black",
          size = 1
        )) + 
  labs(title=expression(chi[p]^2),
       x="",
       y="") 

plot_grid(pb,pb2,  labels = c('A', 'B')) 


```