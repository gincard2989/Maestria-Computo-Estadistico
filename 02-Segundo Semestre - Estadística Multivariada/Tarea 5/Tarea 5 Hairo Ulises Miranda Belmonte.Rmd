---
title: "Tarea 5  Estadística Multivariada"
author: "Hairo Ulises Miranda Belmonte"
date: "15 de Marzo del 2019"
output:
  html_document:
    code_folding: hide #echo=TRUE hide code its default
    
    toc: true
    toc_float: true
    # number_sections: true
    theme: readable
    highlight: textmate 
    fig_width: 7
    fig_height: 6
    fig_caption: true
       
    
---

EJERCICIO 1
---------------

**1. Uso de la regresó lineal simple.**

**(a) Utilice el conjunto de datos /states.rds/.**

```{r message=F}
# Bibliotecas

library("magrittr")
library("knitr")
library("kableExtra")
library("stats")
library("corrplot")
library("DataExplorer")
library("ggpubr")
library("gridExtra")
library("plotly")
library("ggfortify")
library("normtest") 
library("nortest") 
library("tidyverse")
# Direccion
#getwd()
#setwd("C:/Users/h_air/Desktop/CIMATMCE/
     # Semestre_2/Multivariado/Tarea/Dr. Rodrigo/Tarea 5")
```

```{r message=F}
states <- readRDS("states.rds") # cargar datos
```


**(b) Ajusta un modelo que prediga la energía consumida per capita (energy) con respecto al porcentaje de residentes que viven en áreas metropolitanas (metro). Reporta lo siguiente:**

* Examina / gráfica los datos antes de aplicar el modelo

```{r message=F}
states <- readRDS("states.rds")
```

Previo a realizar el análisis gráfico retiramos los valores $NA$ a las variables *energy* y *metro*
```{r message=F}

states2 <- cbind(states$energy,states$metro) %>%  as.data.frame
colnames(states2) <- c("energy","metro")
# optamos por eliminar la observaciÃƒÂ³n 
states2 <- states2 %>% drop_na
```

Se realiza un gráfico de correlación para observar la relación lineal entre las dos variables de interes.

```{r message=F}
corrplot.mixed(cor(states2))
```

Existe una relación inversa entre la variable energía percapita respecto al porcentaje de residentes que viven en áreas metropolitanas.

Se presentan gráficos exploratorios previo a realizar el  modelo.

```{r message=F}

p1 <- ggqqplot(states2$energy) + theme_gray() +  labs(title="QQ-plot",
                                                      subtitle = "residentes ")
p2 <- states2[1] %>%  ggplot(aes(x=energy)) + 
  geom_histogram(color="black", fill="white") +  labs(title="Histograma",
                                                      x="residentes",
                                                      subtitle = "residentes ")
p3 <- ggqqplot(states2$metro) + theme_gray() +  labs(title="QQ-plot",
                                                     subtitle = "Energía Consumida per capita")

p4 <- states2[2] %>%  ggplot(aes(x=metro)) + 
  geom_histogram(color="black", fill="white") +  labs(title="Histograma",
                                                      x="energía",
                                                      subtitle = "Energía Consumida per capita")
grid.arrange( p3, p4,p1, p2, nrow = 1)
```

Se tiene cuatro gráficos, los primeros dos (de izquierda a derecha), se observa el QQ-plot de la energía consumida percapita, se observa una cola pesada. La variable el número de residentes cuenta con colas ligeramente pesadas; no obstante, con su respectivo histograma se observa que datos atipicos afectan la forma de la distrbución de la variable. De esta manera, las variables no parecen distribuirce de forma normal, presentando datos en los extremos que afecten su comportamiento.

A continuación, se presenta un gráfico de dispersión de la energía percapita respecto al número de residentes, con el cual   se puede observar algunos valores atipicos.


```{r message=F}
states2 %>%  ggplot() +  aes(x=metro, y = energy) + geom_point() +
  xlab("Energía Consumida per capita") + ylab("residentes en áreas metropolitanas") 
```



*ii. Imprime e interpreta el modelo*

Realizamos el siguiente modelo
$$Energy = \beta_0+\beta_1metto$$
```{r message=F}
m1 <- lm(states2$energy~states2$metro)
summary(m1)
```

En el modelo se observa que tanto el intercepto y la variable de residentes en área metropolitana, son significativos al $99\%$ y $100\%$ de significancia. La variable *metro* presenta una relación inversa, lo cual índica que a un incremento de una unida en el número de residentes en el área metropolinada, reducirá $-2.2871$ la energía consumida percapita. El $R^2$ es del $0.1154$, indicando que la covariable no explica en su totalidad la variabilidad de la energía percapita.  




** iii. Gráfica el modelo para buscar desviaciones de los supuestos de modelado**

```{r message=F}
# Supuestos del modelo Función
diagPlot<-function(m1){
  p1<-ggplot(m1, aes(.fitted, .resid))+geom_point()
  p1<-p1+stat_smooth(method="loess")+geom_hline(yintercept=0, col="red", linetype="dashed")
  p1<-p1+xlab("Valores Ajustados")+ylab("Residuales")
  p1<-p1+ggtitle("Residuales vs Valores Ajustados")
  
  p2<-ggqqplot(m1$residuals) + theme_gray() + labs(title="QQ-plot",
                                                   subtitle = "residuales")
  
  
  p3<-ggplot(m1, aes(.fitted, sqrt(abs(.stdresid))))+geom_point(na.rm=TRUE)
  p3<-p3+stat_smooth(method="loess", na.rm = TRUE)+xlab("Fitted Value")
  p3<-p3+ylab("Root Residuales estandarizado")
  p3<-p3+ggtitle("Scale-Location")+theme_bw()
  
  p4<-ggplot(m1, aes(seq_along(.cooksd), .cooksd))+geom_bar(stat="identity", position="identity")
  p4<-p4+xlab("Obs. Number")+ylab("Cook's distance")
  p4<-p4+ggtitle("Cook's distance")+theme_bw()
  
  p5<-ggplot(m1, aes(.hat, .stdresid))+geom_point(aes(size=.cooksd), na.rm=TRUE)
  p5<-p5+stat_smooth(method="loess", na.rm=TRUE)
  p5<-p5+xlab("Leverage")+ylab("Standardized Residuals")
  p5<-p5+ggtitle("Residual vs Leverage Plot")
  p5<-p5+scale_size_continuous("Cook's Distance", range=c(1,5))
  p5<-p5+theme_bw()+theme(legend.position="bottom")
  
  p6<-ggplot(m1, aes(.hat, .cooksd))+geom_point(na.rm=TRUE)+stat_smooth(method="loess", na.rm=TRUE)
  p6<-p6+xlab("Leverage hii")+ylab("Cook's Distance")
  p6<-p6+ggtitle("Cook's dist vs Leverage hii/(1-hii)")
  p6<-p6+geom_abline(slope=seq(0,3,0.5), color="gray", linetype="dashed")
  p6<-p6+theme_bw()
  
  return(list(rvfPlot=p1, qqPlot=p2, sclLocPlot=p3, cdPlot=p4, rvlevPlot=p5, cvlPlot=p6))
}
```

Realizamos el anáisis a los residuales del modelo. El grpafico superior izquierdo muestra el ajuste de la regresión a las observaciones, se observan un par de observaciones que no son ajustados por la recta de regresión. El gráfico superior derecho se presentan los residuales respecto a los valores ajustados,  en el cual claramente se observa como los residuales siguen la tendencia del ajuste de la regresión, indicando correlación etre los rsiduos y las estimaciones ($\epsilon'\hat{y} \neq 0$).Por otro lado, asumimos que los residuales on ruido blanco; sin embargo, en las gráficas inferiores se observan que los residuales no son normales.

```{r message=F}
# Modelo ajustando a regresión
p1 <- ggplot(states2, aes(x = metro, y = energy)) + 
  geom_point() +
  stat_smooth(method = "lm", col = "red")  + 
  xlab("Energía Consumida per capita") + 
  ylab("residentes en áreas metropolitanas") +
  labs(title = "Ajuste de regresión")
diagPlts<-diagPlot(m1)
p2 <- diagPlts$rvfPlot
p3 <- diagPlts$qqPlot
p4 <- as.data.frame(m1$residuals) %>%  ggplot(aes(x=m1$residuals)) + 
  geom_histogram(color="black", fill="white") +  labs(title="Histograma",
                                                      x="residentes")
grid.arrange( p1, p2,p3, p4, nrow = 2)
```

Se utiliza la prueba de Shapiro y Watstos de normalidad sobre los residuales. En base al críterio del p-valor, se tiene evidencia suficiente para rechazar la hipótesis de normalidad en los residuales.
$$H_0: normalidad$$
```{r message=F}
shapiro.test(m1$residuals)
```


Ahora, observamos si los datos atipicos influyen en los resultados.

```{r message=F}
p1 <- diagPlts$sclLocPlot
p2 <- diagPlts$cdPlot
p3 <- diagPlts$rvlevPlot
p4 <- diagPlts$cvlPlot
grid.arrange( p1, p2,p3, p4, nrow = 2)
```

Utilizando la desviación estandar de los residuales (scale-location) se observa la siperción de los residuales sobre los valores ajustados del modelo, se observa que la dispersión de los residuales no es la misma para todo el rango de los valores ajustados, mostrando una linea de ajuste cada vez menos horizontal, sugeriendo que el modelo presenta efectos de heterocedasticidad en los residuos. Por otra parte, la distancia de Cook's nos indica la influencia de los datos sobre los resultados del modelo, la figura superior derecha, muestra con barras, la existencia de 5 observaciones que pueden estar influyendo en los resultados del modelo; asimismo, con el grafico inferior derecho, la distancia de Cook's y el laverage hill, indican observaciones atipicas en las covariables. 

Se procede a retirar los valores atipicos para actualizar el modelo. se retiran las observaciones $18,50,2,43$ del modelo.

```{r message=F}
m2 <- update(m1, subset=(1:35)[-c(18,50,2,43)])
summary(m2)
```

Los coeficientes del intercepto y los residentes en el área metropolitana son significativos, casi al $100\%$. El $R^2$ mejora ligeramente, ajustando mejor el modelo sin observaciones atipicasrespecto al modelo anterior. De esta forma, un cambio de una unidad en el número de residentes en el área metropolitana, reducirá en $-1.7964$ la energía percapita. El $F-statistic$ indica que el modelo en general explica bien.

Evaluamos normalidad en los residuos del nuevo modelo. Se observa que los residuales al retirar los datos atipicos se parecen más a observaciones provenientes de distribuciones normales.

```{r message=F}
p1 <- diagPlot(m2)$qqPlot
p2 <- as.data.frame(m2$residuals) %>%  ggplot(aes(x=m2$residuals)) + 
  geom_histogram(color="black", fill="white") +  labs(title="Histograma",
                                                      x="residentes")
grid.arrange( p1, p2, nrow = 1)
shapiro.test(m1$residuals)
jb.norm.test(m1$residuals) 
```

Con la prueba de Shapiro y Watson, no se tiene evidencia suficiente para rechazar la hipótesis nula, por lo tanto los residuales son normales.
```{r message=F}

shapiro.test(m2$residuals)
```




**(c) Selecciona uno o más predictores adicionales para agregar al modelo y repita los pasos anteriores.¿Este modelo significativamente mejor que el modelo con la variable / metro / solo comoúnico predictor?**

Como en el caso anterior retiramos los valores $NA$ de la base. Realizamos un gráfico de correlación para seleccionar variables con mayor relación lineal respecto a la energía percapita.

```{r message=F}
# variables continuas
states3 <- states[c(1,6:dim(states)[2])]
# Alaska. Distric Columbia y Hawaii no tienen missimvalues

states3Names <- states3 %>% names
states3 <- states3 %>% drop_na
corrplot.mixed(cor(states3[c(2:dim(states3)[2])]))
# miles toxic metro green house senate
```

La energia presenta correlación respecto a la variables toxic, hause, metro, miles, green y sense; algunas relación positiva, y otra a manera negativa.

```{r message=F}
# Filtramos a una nueva base
# sin distrito de columbia
states3 <- cbind(states3$energy, states3$metro,states3$miles,
                 states3$toxic,states3$green,states3$house,states3$senate) %>%  as.data.frame
colnames(states3) <- c("energy","metro","miles","toxic","green","house","senate")
```

Por medio de los valores propios de la matriz de correlación de las observaciones, se bucan indicios de multicolinealidad en los datos.

```{r message=F}

autoval <- eigen(cor(states3[-c(1)])) # sin variable dependiente
val <- autoval$values %>% as.data.frame
indice <- c(1:6)
val <- cbind(val,indice)
valorPlot <- val %>% ggplot() + aes(y=.,x=indice)+ geom_point() + geom_line() +
  labs(title="valores propios", x="# eigenvalues", y="valor propio")
ggplotly(valorPlot)

# Numero de condicion de la matriz
phi <- max(autoval$values)/min(autoval$values)
# poca colinealidad
```


$\lambda_{max}/\lambda_{min}=$ `r toString(phi)`, indicando algo de multicolinealidad; i.e, covariables se afectan entre si.

Realizamos el modelo 
$$energy=\beta_0+\beta_1metro+\beta_2miles+\beta3toxic+\beta4green+\beta5house+\beta5senate+\epsilon$$
```{r message=F}
m3 <- lm(states3$energy~., data=states3)
summary(m3)
```

Solamente el coeficeinte de la variable  toxic y green son significativas casi al $100%$, la $R^2$ ajustada y sin ajustar, indican buen ajuste en el modelo; no obstate, muchas variables tienen significacia estadísittca. 

Planteamos el siguiente modelo:
$$energy=\beta_0+\beta_1metro +\beta2house+\epsilon$$
```{r message=F}
m3 <- lm(states3$energy ~  + states3$metro + states3$house)
summary(m3)
```

Se tiene que solo el coeficiente de  *house* es significativa a casi el $100%$, y el coeficiente de metro se aproxima a ser sifnificativa al $90%$; a su vez, el valor del $R^2$ ajustado, y sin ajustar, disminuye.

*iii. Gráfica el modelo para buscar desviaciones de los supuestos de modelado**

Ahora, le realizamos pruebas a los residuales del modelo anterior para detectar violaciones en el supuesto

```{r message=F}
diagPlts<-diagPlot(m3)
p1 <- diagPlts$rvfPlot 
p2 <- diagPlts$qqPlot
p3 <- as.data.frame(m3$residuals) %>%  ggplot(aes(x=m3$residuals)) + 
  geom_histogram(color="black", fill="white") +  labs(title="Histograma",
                                                      x="residentes")
grid.arrange(p1,p2,p3,nrow=1)
```
Se observa, correlación en los residuales y a su vez, la dispersión de ellos en la primera grafica nos indican efectos de heterocedasticidad en el modelo; por otro lado, vemos que los residuales parecen normales en el centro de la distribución , pero no en las colas.

Aplicamos el test de normalidad sobre los residuos del modelo, podemos decir, que se tiene evidencia para rechazar la hipotesis nula de normalidad en los residuales.

```{r message=F}
shapiro.test(m3$residuals)
```


Ahora, realizamos gráficos para detectar valores atipicos que afecten los resultados en el modelo.
```{r message=F}
# no normales

p1 <-diagPlts$sclLocPlot
p2 <- diagPlts$cdPlot
p3 <- diagPlts$rvlevPlot
p4 <- diagPlts$cvlPlot
grid.arrange(p1,p2,p3,p4, nrow=2)
```
 Es claro que utilizando los estadísticos de Cook´s y los valores leverege, se detecta la existencia de un grupo de observaciones atipicas en las covariables que ocasiones una mala especificación en el modelo. Se retiran las observaciones $16,48,41,12,32$.
 
 Se procede a retirar los valores atipicos. Planteamo de nuevo el modelo:
 
 $$energy=\beta_0+\beta_1metro +\beta2house+\epsilon$$
 

```{r message=F}
StanRes1 <- rstandard(m3)
CouponRate <- states3$energy
Case <-c(1:51)
m4 <- update(m3, subset=(1:35)[-c(16,48,41,12,32)])
summary(m4)
```
Retirando valores atipicos, se observa que los coeficientes del intercepto,  metro y house son significativas, al $100\%$, $99\%$ y $95\%$. Con un $R^2$ de $0.4706$, lo cual es un ajuste ligeramente bueno. El valor $F$ indica que el modelo en global es adecuado. De esta manera, un incremento de una unidad en la variable *house*, genera un cambio de $-0.9409$ en la energía consumida percapita; a su vez, un incremento de una unidad en el número de residentes en el área metropolitana, hace que la energia consumida cambie en $-0.9409$.

Realizamos el analisis de normalidad en los residuales del modelo.


```{r message=F}
p1 <-diagPlot(m4)$qqPlot
p2 <- as.data.frame(m4$residuals) %>%  ggplot(aes(x=m4$residuals)) + 
  geom_histogram(color="black", fill="white") +  labs(title="Histograma",
                                                      x="residentes")
grid.arrange(p1,p2,nrow=1)
```
Se observa que los residuales se parecen ligeramente a una normal; sin embargo, utilizamos la prueba de Shapiro y Watson para argumentar al respecto.

Bajo el crpiterio del p-valor, no se tiene evidencia suficiente para rechazar la hipótesis nula; por lo tanto los residuales del modelo se distribuyen de forma normal.
```{r message=F}
shapiro.test(m4$residuals)
```

Construimos intervalos de confianza a los coeficientes de la regresión 

```{r message=F}
intervalo <- round(confint(m4,level=0.95),3)
Tabla <- data.frame(parametros=m4$coefficients, ICInferior=intervalo[,1],
                    ICUpper=intervalo[,2])

rownames(Tabla) <-c("Intercepto","metro", "house")
Tabla %>% kable %>% kable_styling
```{r message=F}
```

Para constastar los resultado realizamos un análisis de varianza con la prueba anova. Se observa que los factores que se eligen son significativos para la variable respuesta.
```{r message=F}
anova(m3)
```



EJERCICIO 2
---------------

*2. Los datos del archivo costoliving.txt enumeran algunas estadÃƒ???sticas del costo de vida para cada uno
de los 50 estados de los USA. Los tres costos son:  alquileres de apartamentos (rent) costo de casas  (house)
el índice de costo de vida. (cost of live). resto de variables (income) and (pop)

```{r message=F}
# importando datos
costolive <- read.table("costofliving.txt", header = T)
```

Realizamos un analisis gráfico de las variables. 

```{r message=F}
# Exploratorio de datos
p1 <- ggqqplot(costolive$rent) + theme_gray() +  labs(title="QQ-plot",
                                                      subtitle = "alquilier departamento")
p2 <- costolive[2] %>%  ggplot(aes(x=rent)) + 
  geom_histogram(color="black", fill="white") +  labs(title="Histograma",
                                                      x="dolares",
                                                      subtitle = "alquilier departamento")
p3 <- ggqqplot(costolive$house) + theme_gray() +  labs(title="QQ-plot",
                                                       subtitle = "Costo de casa")
p4 <- costolive[3] %>%  ggplot(aes(x=house)) + 
  geom_histogram(color="black", fill="white") +  labs(title="Histograma",
                                                      x="dolares",
                                                      subtitle = "Costo de casa")
grid.arrange(p1, p2,p3,p4, nrow = 2)
```

Podemos obsservar que las variables del costo de casa y alquiler de departamento presentan colas pesadas, las cueles pueden ser generadas por datos atipicos.

```{r message=F}
p5 <- ggqqplot(costolive$COL) + theme_gray() +  labs(title="QQ-plot",
                                                     subtitle = "Costo de vida")
p6 <- costolive[4] %>%  ggplot(aes(x=COL)) + 
  geom_histogram(color="black", fill="white") +  labs(title="Histograma",
                                                      x="dolares",
                                                      subtitle = "Ingresos medios")
p7 <- ggqqplot(costolive$income) + theme_gray() +  labs(title="QQ-plot",
                                                        subtitle = "Costo de casa")
p8 <- costolive[6] %>%  ggplot(aes(x=income)) + 
  geom_histogram(color="black", fill="white") +  labs(title="Histograma",
                                                      x="dolares",
                                                      subtitle = "Ingresos medios")

p9 <- ggqqplot(costolive$pop) + theme_gray() +  labs(title="QQ-plot",
                                                     subtitle = "Población")
p10 <- costolive[5] %>%  ggplot(aes(x=pop)) + 
  geom_histogram(color="black", fill="white") +  labs(title="Histograma",
                                                      x="Población",
                                                      subtitle = "Población")


grid.arrange(p5, p6,p7,p8,p9,p10, nrow = 3)
```

El resto de las variables presentan un comportamiento similar a las anteriores, colas pesadas, y algunas observaciones atipicas.

A continuación presentamos gráficos de disperción de las variables respuestas respectos las covariables a utilizar en el modelo.

```{r message=F}
p11 <- costolive %>%  ggplot() +  aes(x=income, y = rent ) + geom_point() +
  ylab("Alquiler departamento") + xlab("Ingreso medio") 
p12 <- costolive %>%  ggplot() +  aes(x=pop, y = rent ) + geom_point() +
  ylab("Alquiler departamento") + xlab("Poblacion") 

p13 <- costolive %>%  ggplot() +  aes(x=income, y = house ) + geom_point() +
  ylab("Costo de casa") + xlab("Ingreso medio") 
p14 <- costolive %>%  ggplot() +  aes(x=pop, y = house ) + geom_point() +
  ylab("Costo de casa") + xlab("Poblacion") 

p15 <- costolive %>%  ggplot() +  aes(x=income, y = COL ) + geom_point() +
  ylab("Costo de vida") + xlab("Ingreso medio") 
p16 <- costolive %>%  ggplot() +  aes(x=pop, y = COL ) + geom_point() +
  ylab("Costo de vida") + xlab("Poblacion") 

grid.arrange(p11, p12, p13, p14, p15, p16, nrow = 3)
```

A primera vista se presentan observaciones en las covariables atipicas.

Se realiza un gráfico de correlación para ver el grado de relación lineal entre las variables respuestas y covariables.

```{r message=F}
corrplot.mixed(cor(costolive[-c(1)]))
```

Se observa una relación negativa entre las variables, con excepción a la población de cada estado.

**(a) Realiza una regresíon  lineal multivariada para explicar estas tres métricas en terminos de las
poblaciones estatales e ingresos medios. Ã‚Â¾Son ÃƒÂºtiles estas variables independientes para explicar conjuntamente las variables de costo?**

```{r message=F}
Y <- costolive[c(2,3,4)]
modelo <- lm(as.matrix(Y) ~ costolive$income + costolive$pop)
summary(modelo)
```


Tenemos el modelo multivariado en la parte de arriba, para las tres respuestas. La respuestade la variable costo de renta presenta a sus tres coeficientes significativos a diferentes niveles de significancia; de esta manera incrementos de una unidad en el ingreso promedio aumentan en los costos de la renta, asimismo,  incrementos de una unidad en el número de habitantes generan incrementos en el costo de renta.

El modelo de la respuesta costo de habitación cuenta con los coeficientes de las covariables significativos a distintos niveles, pero no el coeficiente de la constante. 

En la respuesta del coosto de vida,  el coeficiente del ingreso medio es significativo, ya que incrementos de ua unidad del ingreso medio genera cambios del del $4.351e-01$, los cuales son pequeños pero significativos.

Los ajustes del modelo por medio del $R^2$ no son los mejores, ya que reporta niveles menores al $.5$.

Ahora realizamos la prueba de normalidad a los residuales de las respuestas. 

```{r message=F}
B <- modelo$coefficients
residuals <- modelo$residuals
yest <- modelo$fitted.values
i <- 1:3
sapply(i , function(i) shapiro.test(modelo$residuals[,i]))
```
En conclusión  se tiene evidencia suficiente para rechazar la hipótesis nula de normalidad en los residuales bajo el críterio del p-valor.

Vemos que los residuales no estén correlacionados con los ajustes de las respuestas y que la suma de residuales sea cero.
```{r message=F}
# supuestos del modelo e'yest
t(modelo$residuals)%*%yest %>% as.data.frame %>% kable %>% kable_styling
```

Suma de residuales igual a cero
```{r message=F}
colMeans(modelo$residuals) %>% as.data.frame %>% kable %>% kable_styling
```

Ahora, por medio del análisis de varianza utilizamos la prueba MANOVA para rectificar el resultado de la regresión

```{r message=F}
res.man <- manova(as.matrix(Y)~ as.matrix(cbind( costolive$income,costolive$pop)))
summary.aov(res.man)
# factores significativos
```

Nos indica que vajo el críterio del p-valor los factores son significativos para cada respuesta.

Se retiran valores atipicos para mejorar el modelo. Quitamos aquellos valores atipicos que se presenten para cada respuesta los cuales son: $5,12,20,32,8$. Ajustamos de nuevo el modelo y tenemos lo siguiente:

```{r message=F}
# retirando outliers
modelo_outlier <- update(modelo, subset=(1:35)[-c(5,12,20,32,8)])
summary(modelo_outlier)

```

Primero, se observa que el $R^2$ ajustado, y sin ajustar, mejora, indicando un mejor ajuste para las tres respuestas. Segundo, para la primera respuesta, que es el costo de la rentas, los coeficientes del intercepto, ingreso medio, y población, son significativas a diferentes nveles, ambos afectan de forma positiva al costro de renta.

En el caso de la respuesta, costo de casa, el intercepto no es significativo, pero si las covariables, por lo que un incremento en el ingreso medio genera un incremento en el costo de las casas aproximado de $4.264146$, y un incremento en una unidad de la población genera u aumento del costo de casas del $0.003585$.

En la respuesta delcosto de vida, solo el ingreso medio y el intercepto son significativos; de esta manera, un incremento de una unidad en el ingreso medio, genera un cambio en el índice del costo de vida del $8.235e-01$ aproximadamente.

Ahora evaluamos normalidad en los residuales.

```{r message=F}
i <- 1:3
sapply(i , function(i) shapiro.test(modelo_outlier$residuals[,i]))
```

Como se observa ahora no se tiene evidencia suficiente para rechazar la hipótesis nula, por lo tanto los residuales se distribuyen de forma normal.

Constuimos intervalos de confianza

```{r message=F}
intervalo <- round(confint(modelo_outlier,level=0.95),3)
rownames(intervalo) <-c("rent:intercepto ","rent:income ", "rent:pop",
                        "house:intercepto ","house:income ", "house:pop",
                        "COL:intercepto ","COL:income ", "COL:pop")
intervalo %>% kable %>% kable_styling
```



En los tres modelos la variable del número de población estados no era muy significativa. Para esto, se realiza la prueba de verosimilitud para bajo la hipótesis nula $H_0=\beta_2=0$, que el coeficiente de la población no es necesario para explicar a las respuestas "en conjunto".

```{r message=F}

# likelihood ratio test
ones <- costolive$rent %>% length %>% diag %>% diag %>% as.matrix
X1 <- costolive$income %>% as.matrix
X2 <- costolive$pop %>% as.matrix
Z <- cbind(ones, X1, X2)
Y <- costolive[c(2,3,4)] %>% as.matrix
B <- solve(t(Z)%*%Z)%*%t(Z)%*%Y
Yest <- Z%*%B
e <- Y - Yest
RSS <- t(e)%*%e
Z2 <- costolive$income %>% as.matrix
B2 <- solve(t(Z2)%*%Z2)%*%t(Z2)%*%Y
Yest2 <- Z2%*%B2
e2 <- Y - Yest2
RSS2 <- t(e2)%*%e2
# Wilks' lambda
H <-RSS2- RSS
E <- RSS
lambdaWilks <- det(E)/(det(E+H))

m <- 3
r <- 2
n <- length(Y[,1])
q <- 1

Fcritico <- qf(.01, m*(r-q), n-r-m, lower.tail = F)

```

$$\Lambda=\frac{|E|}{|E+H|}= 0.03529033$$ 
$$F_{3,46}=4.238306$$ 
$$\Lambda \leq F_{3,46}$$
Por lo tanto,  no se tiene evidencia suficiente para rechazar la hipótesis nula; entonces, la variable de población no explica a la respuestas en su conjunto.






**(b) Ajusta tres modelos de regresión lineal de manera separada y verica la utilidad de las variables independientes en cada uno ellos. Compara los resultados con los obtenidos en el inciso (a)**

MODELO 1:
$$rent=\beta_0+\beta_1income+\beta_2pop+\epsilon$$
```{r message=F}

modelo1 <- lm(costolive$rent ~ costolive$income + costolive$pop)
summary(modelo1)
```
Observamos significancia estadística para los tres coeficientes, pero un $\R^2$ ajustado, y sin ajustar bajo.

MODELO 2:
$$house=\beta_0+\beta_1income+\beta_2pop+\epsilon$$
```{r message=F}
modelo2 <- lm(costolive$house ~ costolive$income + costolive$pop)
summary(modelo2)
```



El coeficiente del intercepto no es significativo, el del ingreso medio es significativo y posotivo, pero el de la población es significativo al $95\%$. El ajuste es bajo ya que el $R^2$ es menor al $.5$.


MODELO 3:
$$COL=\beta_0+\beta_1income+\beta_2pop+\epsilon$$
```{r message=F}
modelo3 <- lm(costolive$COL ~ costolive$income + costolive$pop)
summary(modelo3)
```

En este modelo, solo el coeficiente y el ingreso medio son significativos, por lo tento incrementos en el ingreso medio de una unidad generan en promedio un aumneto del índice de costo de vida del $4.351e-01$. 



Ahora, tratamos de mejorar el modelo uno mediante la detección de ouliers, y analisando sus residuales.

*MODELO 1*
MODELO 1:
$$rent=\beta_0+\beta_1income+\beta_2pop+\epsilon$$

```{r message=F}
diagPlts<-diagPlot(modelo1)
plot0 <- diagPlts$rvfPlot
# correlaciÃƒÂ³n entre residuales y ajustados
plot01 <- diagPlts$qqPlot
# colas pesadas
plot02 <- as.data.frame(modelo1$residuals) %>%  ggplot(aes(x=modelo1$residuals)) + 
  geom_histogram(color="black", fill="white") +  labs(title="Histograma",
                                                      x="residentes")

# outliers
grid.arrange(plot01, plot02, nrow = 1)
```

Onservamos que la distribución de los residuales tiene colas pesadas, y alguno que otro valor atipico. Aplicando test de normalidad a los residuales obtenemos lo siguiente:

```{r message=F}
shapiro.test(modelo1$residuals)
```
Bajo el crpiterio del p-valor los residuales no son normales.

Ahora detectamos outliers que influyan en el resultado del modelo.
```{r message=F}
# no normales
plot1 <- diagPlts$sclLocPlot
# dijimos que existÃƒ???a correlaciÃƒÂ³n 
plot2 <- diagPlts$cdPlot
# se detecta valor atipico que genera influencia en respuesta
plot3 <- diagPlts$rvlevPlot
# exixten datos que afectan observaciones
plot4 <- diagPlts$cvlPlot
#  retirar ourlier del modelo
grid.arrange(plot1, plot2, plot3, plot4, nrow = 2)
```

Con la distancia de cook's se detectan valores atipicos que afecten en los resultados del modelo; con el levereg nos menciona que existe algun valor en alguna covariable que es extremo (atipico); a su vez, con el gráfico superior izquierdo, vemos como los residuales siguen el patron de los valores ajustados, con una dispersión que incrementa en el rango de los valores ajustados en el modelo1, por lo tanto da indicios de heterocedasticidad.

Retiramos los valores qtipicos de las observaciones $5,12,21,32,44$, y actualizamos el modelo 1
```{r message=F}

modelo1_outlier <- update(modelo1, subset=(1:35)[-c(5,12,21,32,44)])

summary(modelo1_outlier)

```

Obtenemos significancia en los tres coeficientes del modelo, todos con una relación positiva, y un $R^2$ cercana a $.5$, a no ajustada, indicando una mejora en el ajuste del modelo.


```{r message=F}
plot5 <- diagPlot(modelo1_outlier)$qqPlot
plot6 <- as.data.frame(modelo1_outlier$residuals) %>%  ggplot(aes(x=modelo1_outlier$residuals)) + 
  geom_histogram(color="black", fill="white") +  labs(title="Histograma",
                                                      x="resuduals")
grid.arrange(plot5,plot6, nrow = 1)
```

Observamos la gráfica sin los outliers, la distribución de los residuales mejora en las colas, pero no tanto en el centro. Utilizamos el test de normalidad.
```{r message=F}
shapiro.test(modelo1_outlier$residuals)
 
```

se tiene un estadístico $W$ cerano a uno, pero un p-valor que no rechaza la hpótesis nula pero solo al $97%$ aproximadamente.
Realizamos intervalos de ocnfianza para los coeficientes estimados en el modelo uno.

```{r message=F}
intervalo <- round(confint(modelo1_outlier,level=0.95),3)
Tabla <- data.frame(parametros=modelo1_outlier$coefficients, ICInferior=intervalo[,1],
                    ICUpper=intervalo[,2])
rownames(Tabla) <-c("Intercepto","income", "pop")
Tabla %>% kable %>% kable_styling
```



*MODELO 2*
MODELO 2:
$$house=\beta_0+\beta_1income+\beta_2pop+\epsilon$$

Se realiza el mismo análisis al modelo 2.

```{r message=F}
diagPlts<-diagPlot(modelo2)
plot0_m2 <- diagPlts$rvfPlot
# correlaciÃƒÂ³n entre residuales y ajustados
plot01_m2 <- diagPlts$qqPlot
# colas pesadas
plot02_m2 <- as.data.frame(modelo2$residuals) %>%  ggplot(aes(x=modelo2$residuals)) + 
  geom_histogram(color="black", fill="white") +  labs(title="Histograma",
                                                      x="residentes")

# outliers
grid.arrange(plot01_m2, plot02_m2, nrow = 1)
```

Los residuales parecen no distribuirse normales, pero se detecta mucho valor atipico. Bajo el test de normalidad se rechaza la hipótesis nula.

```{r message=F}
shapiro.test(modelo1$residuals)
```

Se observa a detectar valores atipicos que afecten el resultado del modelo
```{r message=F}
plot1_m2 <- diagPlts$sclLocPlot
# dijimos que existÃƒ???a correlaciÃƒÂ³n 
plot2_m2 <- diagPlts$cdPlot
# se detecta valor atipico que genera influencia en respuesta
plot3_m2 <- diagPlts$rvlevPlot
# exixten datos que afectan observaciones
plot4_m2 <- diagPlts$cvlPlot
#  retirar ourlier del modelo
grid.arrange(plot1_m2, plot2_m2, plot3_m2, plot4_m2, nrow = 2)
```

Observamoscuatro valores atipocos en la distancia de cooks, que superan el valor uno, los cuales afectan el resultado del modelo; por otro lado, en el gráfico superior izquierdo, se observa a los residuales que crecen conforme el rango de los valores ajustados aumenta, de esta manera, se dice que la variable no es constante.

Se procede a detectar y retiras los valores atipico. Se retiran las observaciones $5,8,12,44, y re-ajustamos el modelo

```{r message=F}
# Les quito missing por que tienen influenza en respuesta
modelo2_outlier <- update(modelo2, subset=(1:35)[-c(5,8,12,44)])
summary(modelo2_outlier)
```

El coeficiente $R^2$ incrementa a casi punto cinco, el intercepto no es significativo, pero el ingreso y la población lo son al, $99\%$ y $95\%$ respectivamente.

Evaluado normalidad en los residuales:
```{r message=F}
plot5_m2 <- diagPlot(modelo2_outlier)$qqPlot
plot6_m2 <- as.data.frame(modelo2_outlier$residuals) %>%  ggplot(aes(x=modelo2_outlier$residuals)) + 
  geom_histogram(color="black", fill="white") +  labs(title="Histograma",
                                                      x="residentes")
grid.arrange(plot5_m2,plot6_m2, nrow = 1)
```

Parece que los residuales se aproximan a la distribución normal. Se utiliza el tes de normalidad y se tiene:


```{r message=F}
shapiro.test(modelo2_outlier$residuals)
```

Se tiene evidencia suficiente para rechazar la hipótesis nuela al $95%$, por lo tanto los residuales son normales.

Se realizan intervalos de confianza a los coeficientes del modelo 2

```{r message=F}
intervalo <- round(confint(modelo2_outlier,level=0.95),3)
Tabla <- data.frame(parametros=modelo2_outlier$coefficients, ICInferior=intervalo[,1],
                    ICUpper=intervalo[,2])
rownames(Tabla) <-c("Intercepto","income", "pop")
Tabla %>% kable %>% kable_styling

```


**MODELO 3**
MODELO 3:
$$COL=\beta_0+\beta_1income+\beta_2pop+\epsilon$$
Aplicamos al tercer modelo lo anterior, mejorar el modelo retirando valores atipicos.

```{r message=F}
diagPlts<-diagPlot(modelo3)
plot0_m3 <- diagPlts$rvfPlot
# correlaciÃƒÂ³n entre residuales y ajustados
plot01_m3 <- diagPlts$qqPlot
# colas pesadas
plot02_m3 <- as.data.frame(modelo3$residuals) %>%  ggplot(aes(x=modelo2$residuals)) + 
  geom_histogram(color="black", fill="white") +  labs(title="Histograma",
                                                      x="residentes")

# outliers
grid.arrange(plot01_m3, plot02_m3, nrow = 1)
```

Observamos que os residuales del modelo tres no son normales, y presentan valores atipicos. El test de normalidad rechaza la hipótesis nula de normalidad en los residuales.
```{r message=F}
shapiro.test(modelo3$residuals)
```

Se observa si los valores atipicos afectan a los resultados del modelo.

```{r message=F}
plot1_m3 <- diagPlts$sclLocPlot
# dijimos que existÃƒ???a correlaciÃƒÂ³n 
plot2_m3 <- diagPlts$cdPlot
# se detecta valor atipico que genera influencia en respuesta
plot3_m3 <- diagPlts$rvlevPlot
# exixten datos que afectan observaciones
plot4_m3 <- diagPlts$cvlPlot
#  retirar ourlier del modelo
grid.arrange(plot0_m3, plot1_m3, plot2_m3, plot3_m3, plot4_m3, nrow = 3)
```

El gráfico superior izaquiedo, presentan residuales muy dispersos, pero no de forma constante; el superior derecho, argumenta lo anterior, ya que los resduales tienden a ajustarce a la linea del ajuste de los valores del modelo; por otro lado, la distacia de cooks, detecta cinco valores que pueden ocacionar que el modelo no se desempeñe de manera correcta.

Presentamo el modelo sin los datos atipicos.
```{r message=F}
# Les quito missing por que tienen influenza en respuesta
modelo3_outlier <- update(modelo3, subset=(1:35)[-c(8,12)])
summary(modelo3_outlier)
```

La mejora en el modelo es notoria, los coeficientes del intercepto, ingreso promedio, y población, son significativos a distintos niveles. El valor del $R^2$ no ajustada en del $0.05$, y el ajustado se aproxima a ese valor; a su vez, el estadístico $F$, menciona que a manera global el modelo estpa bien especificado.

De esta manera, cambios en una unidad del ingreso promedio y del número de población afectan de manera positiva al índice de costo de vida en la magnitud de los coeficientes que se observan arriba.

Revisamos normalidad en el modelo 3.

```{r message=F}
plot5_m3 <- diagPlot(modelo3_outlier)$qqPlot
plot6_m3 <- as.data.frame(modelo3_outlier$residuals) %>%  ggplot(aes(x=modelo3_outlier$residuals)) + 
  geom_histogram(color="black", fill="white") +  labs(title="Histograma",
                                                      x="residuals")
grid.arrange(plot5_m3 , plot6_m3, nrow = 1)
```

Sin los valores atipicos os reisduales se aproximan a la normal en las colas, no obstante aún se ve que existen valores que hacen que los residuales no se comporten exactamente con observaciones normales. Por otro lado, si utilizamos el test de normalidad nos indica que no se tiene evidencia suficiente para rechazar la hipótesis nula, por lo cual, los residuales son se distribuyen normales.

```{r message=F}
shapiro.test(modelo3_outlier$residuals)
```

Ahora construimos intervalos de confianza a los coeficentes del modelo 3.
```{r message=F}
intervalo <- round(confint(modelo3_outlier,level=0.95),3)
Tabla <- data.frame(parametros=modelo3_outlier$coefficients, ICInferior=intervalo[,1],
                    ICUpper=intervalo[,2])
rownames(Tabla) <-c("Intercepto","income", "pop")
Tabla %>% kable %>% kable_styling
```




**MODELOS INDIVIDUALES CON LOGARITMO**

A manera de ejercicio, aplicamos logaritmo a los modelos individuales, para ver que ta su mejora; no se pretende presentar todos los resultados anteriores, sin embargo, se realizaron y quedan a su disposución en caso de necesitarlos.
Nota, no se aplico logaritmo a la población.

```{r message=F}
# APLICAMOS LOGARITMO A ALGUNOS MODELOS Y REPETIMOS EJERCICIO

# Exploratorio de datos
costolive$rent <- log(costolive$rent)
costolive$house <- log(costolive$house)
costolive$COL <- log(costolive$COL)
costolive$income <- log(costolive$income)
```

Se presenta descriptivos de la observaciones ahora con logaritmos, sus distribuciones se aproximan a la normal.

```{r message=F}
p1 <- ggqqplot(costolive$rent) + theme_gray() +  labs(title="QQ-plot",
                                                      subtitle = "alquilier departamento logaritmo")
p2 <- costolive[2] %>%  ggplot(aes(x=rent)) + 
  geom_histogram(color="black", fill="white") +  labs(title="Histograma",
                                                      x="dolares",
                                                      subtitle = "alquilier departamento  logaritmo")
p3 <- ggqqplot(costolive$house) + theme_gray() +  labs(title="QQ-plot",
                                                       subtitle = "Costo de casa  logaritmo")
p4 <- costolive[3] %>%  ggplot(aes(x=house)) + 
  geom_histogram(color="black", fill="white") +  labs(title="Histograma",
                                                      x="dolares",
                                                      subtitle = "Costo de casa  logaritmo")
grid.arrange(p1, p2,p3,p4, nrow = 2)
p5 <- ggqqplot(costolive$COL) + theme_gray() +  labs(title="QQ-plot",
                                                     subtitle = "Costo de vida logaritmo")
p6 <- costolive[4] %>%  ggplot(aes(x=COL)) + 
  geom_histogram(color="black", fill="white") +  labs(title="Histograma",
                                                      x="dolares",
                                                      subtitle = "Costo de vida logaritmo")
p7 <- ggqqplot(costolive$income) + theme_gray() +  labs(title="QQ-plot",
                                                        subtitle = "Ingresos medios logaritmo")
p8 <- costolive[6] %>%  ggplot(aes(x=income)) + 
  geom_histogram(color="black", fill="white") +  labs(title="Histograma",
                                                      x="dolares",
                                                      subtitle = "Ingresos medios  logaritmo")

p9 <- ggqqplot(costolive$pop) + theme_gray() +  labs(title="QQ-plot",
                                                     subtitle = "PoblaciÃƒÂ³n ")
p10 <- costolive[5] %>%  ggplot(aes(x=pop)) + 
  geom_histogram(color="black", fill="white") +  labs(title="Histograma",
                                                      x="PoblaciÃƒÂ³n",
                                                      subtitle = "PoblaciÃƒÂ³n USA")


grid.arrange(p5, p6,p7,p8,p9,p10, nrow = 3)
```

La dispersión entre variables respuestas y covariables mejora, en cuestion que se observa relación en casi todos los casos.

```{r message=F}
p11 <- costolive %>%  ggplot() +  aes(x=income, y = rent ) + geom_point() +
  ylab("Alquiler departamento logaritmo") + xlab("Ingreso medio logaritmo") 
p12 <- costolive %>%  ggplot() +  aes(x=pop, y = rent ) + geom_point() +
  ylab("Alquiler departamento logaritmo") + xlab("PoblaciÃƒÂ³n") 

p13 <- costolive %>%  ggplot() +  aes(x=income, y = house ) + geom_point() +
  ylab("Costo de casa logaritmo") + xlab("Ingreso medio logaritmo") 
p14 <- costolive %>%  ggplot() +  aes(x=pop, y = house ) + geom_point() +
  ylab("Costo de casa logaritmo") + xlab("PoblaciÃƒÂ³n") 

p15 <- costolive %>%  ggplot() +  aes(x=income, y = COL ) + geom_point() +
  ylab("Costo de vida logaritmo") + xlab("Ingreso medio logaritmo") 
p16 <- costolive %>%  ggplot() +  aes(x=pop, y = COL ) + geom_point() +
  ylab("Costo de vida logaritmo") + xlab("PoblaciÃƒÂ³n") 

grid.arrange(p11, p12, p13, p14, p15, p16, nrow = 3)
```

La corelación entre variables es mayor respetco a las variables repsuestas y covariales.

```{r message=F}
corrplot.mixed(cor(costolive[-c(1)]))
```





MODELO 1:
$$log(rent)=\beta_0+\beta_1log(income)+\beta_2pop+\epsilon$$
```{r message=F}
# MODELOS

modelo1 <- lm(costolive$rent ~ costolive$income + costolive$pop)
summary(modelo1)
```

El modelo tiene coeficientes significativos. La interpretación es que un incremento porcentual en lo logartmo del ingreso medio afecta a costo de la renta en $4.203e-01$. El $R^2$ mejora ligeramente.



MODELO 2: 
$$log(house)=\beta_0+\beta_1log(income)+\beta_2pop+\epsilon$$
```{r message=F}
modelo2 <- lm(costolive$house ~ costolive$income + costolive$pop)
summary(modelo2)
```

El modelo solo tiene coeficientes de ingreso medio significativo. La interpretación es que un incremento porcentual en lo logartmo del ingreso medio afecta a costo de la renta en $1.001e+00$. El $R^2$ mejora ligeramente.



MODELO 3:
$$log(COL)=\beta_0+\beta_1log(income)+\beta_2pop+\epsilon$$
```{r message=F}
modelo3 <- lm(costolive$COL ~ costolive$income + costolive$pop)
summary(modelo3)

```

El modelo tiene coeficientes significativos el intercepto e ingreso medio. La interpretación es que un incremento porcentual en lo logartmo del ingreso medio afecta a costo de la renta en $3.068e-01 $. El $R^2$ mejora ligeramente.


Detectamos y quitamos outliers para mejorar el modelo, ya que sabemos que estos valores atipicos están afectando la calidad del modelo.


*MODELO1 SIN OUTLIERS*
```{r message=F}
modelo1_outlier <- update(modelo1, subset=(1:35)[-c(5, 8, 12, 21, 29, 32, 44, 50, 51)])
summary(modelo1_outlier)
```

Se observa significancia en sus coeficientes, y un buen ajuste con el $R^2$

```{r message=F}
plot5 <- diagPlot(modelo1_outlier)$qqPlot
plot6 <- as.data.frame(modelo1_outlier$residuals) %>%  ggplot(aes(x=modelo1_outlier$residuals)) + 
  geom_histogram(color="black", fill="white") +  labs(title="Histograma",
                                                      x="residentes")
grid.arrange(plot5,plot6, nrow = 1)
```

 Los residuales se aproximas a distribuirse normales y la prueba de normalidad indica que son normales.
 
 
```{r message=F}

shapiro.test(modelo1_outlier$residuals)
```


*MODELO2 SIN OUTLIERS*
```{r message=F}
modelo2_outlier <- update(modelo2, subset=(1:35)[-c(5,  8, 12, 44, 51)])

summary(modelo2_outlier)
```

Se observa significancia en sus coeficientes, y un buen ajuste con el $R^2$

```{r message=F}
plot5_m2 <- diagPlot(modelo2_outlier)$qqPlot
plot6_m2 <- as.data.frame(modelo2_outlier$residuals) %>%  ggplot(aes(x=modelo2_outlier$residuals)) + 
  geom_histogram(color="black", fill="white") +  labs(title="Histograma",
                                                      x="residentes")
grid.arrange(plot5_m2,plot6_m2, nrow = 1)
```

Los residuales mejoran su distribución a una normal. Bajo el test de normalidad no rechazamos la hipótesis nula de normalidad, por lo tanto los residuales distrinuyen normales.

```{r message=F}
shapiro.test(modelo2_outlier$residuals)
```


*MODELO3 SIN OUTLIERS*
```{r message=F}
modelo3_outlier <- update(modelo3, subset=(1:35)[-c(8,12)])
summary(modelo3_outlier)
```

Se observa significancia en sus coeficientes, y un buen ajuste con el $R^2$

```{r message=F}

plot5_m3 <- diagPlot(modelo3_outlier)$qqPlot
plot6_m3 <- as.data.frame(modelo3_outlier$residuals) %>%  ggplot(aes(x=modelo3_outlier$residuals)) + 
  geom_histogram(color="black", fill="white") +  labs(title="Histograma",
                                                      x="residentes")
grid.arrange(plot5_m3 , plot6_m3, nrow = 1)
```


Los residuales mejoran su distribución a una normal. Bajo el test de normalidad no rechazamos la hipótesis nula de normalidad, por lo tanto los residuales distrinuyen normales.

```{r message=F}
shapiro.test(modelo3_outlier$residuals)
``` 

En conclusión los modelos independientes se ajustan mejor que un modelo en conjunto, ya que existen covariables que en conjunto no afectan a las repsuesta, pero de forma individual sí. Asimismo, los modelos individuales con el ingreso medio en ogaritmos tiene mejor ajuste en base al $R^2$


EJERCICIO 3
---------------


**3. Muchos inversionistas estÃ¡n buscando dividendos que se pagarÃ¡n de los benecios futuros. Los datos del archivos ash hi tech.txt enumeran una serie de caractericas sobre su situaciÃ³n nanciera, hasta septiembre del 2010, de varias empresas de tecnologs e informaci. Las variables resultado a explicar son los dividendos actuales y futuros (current y 60% payout).**

```{r message=F}
situacionFinanciera <- read.table("cash hi tech.txt", header = T)
```



**(a) Desarrolla un modelo de regresiÃ³n multivariada partir de la capitalizaciÃ³n de mercado (market cap), efectivo neto (net cash) y ujo de efectivo (cash ow) y analiza el efecto que tienen conjuntamente respecto a los dividendos.**

Utilizando las respuestas dividendos actuales y futuros, con las covariables ya mencionadas, utilizamos la matriz de covarianza de las covariables y vemos si existe mutlicolinealidad.

```{r message=F}

Y <- cbind(situacionFinanciera$current,situacionFinanciera$payout) %>% as.data.frame
colnames(Y) <- c("current","payout")
X <- situacionFinanciera[c(2,3,4)] 
X <- sapply(i<-1:3, function(i) X[,i] <- as.numeric(gsub(",", "", X[,i])))
colnames(X) <- c("mktcap", "netcash","chflow")
X <- X %>% as.data.frame
```

Vemos el screplot:
```{r message=F}
# parece existir multicolinealidad
valoresPropios <- X %>% cor %>% eigen
val <- valoresPropios$values %>% as.data.frame
indice <- c(1:3)
val <- cbind(val,indice)
valorPlot <- val %>% ggplot() + aes(y=.,x=indice)+ geom_point() + geom_line() +
  labs(title="valores propios", x="# eigenvalues", y="valor propio")
ggplotly(valorPlot)
```


$$\lambda_{max}/\lambda_{min}=42.89294$$

El cual indica colinealidad entre las variables, que claro esta, porque muchas tienen que ver con el ingreso total del mercado de capitales.

```{r message=F}
# Numero de condicion de la matriz
phi <- max(valoresPropios$values)/min(valoresPropios$values)
phi # mucha colinealidad en los datos
```

```{r message=F}
# Exploratorio de datos
p1 <- ggqqplot(X$mktcap) + theme_gray() +  labs(title="QQ-plot",
                                                      subtitle = "CapitalizaciÃ³n del mercado")
p3 <- ggqqplot(X$netcash) + theme_gray() +  labs(title="QQ-plot",
                                                       subtitle = "Efectivo neto")
p5 <- ggqqplot(X$chflow) + theme_gray() +  labs(title="QQ-plot",
                                                     subtitle = "Flujo de efectivo")
grid.arrange(p1, p3, p5, nrow = 1)
```

La observaciones se encunetran dentro del intevalo de confianza pero no parece normales, cuentan con colas pesadad.

```{r message=F}

p11 <- as.data.frame(Y[,1]) %>%  ggplot() +  aes(x=X$mktcap, y = Y$current ) + geom_point() +
  ylab("Dividendo actuales") + xlab("CapitalizaciÃ³n del mercado") 
p12 <- as.data.frame(Y[,1]) %>%  ggplot() +  aes(x=X$netcash, y = Y$current ) + geom_point() +
  ylab("Dividendo actuales") + xlab("Efectivo neto") 
p13 <- as.data.frame(Y[,1]) %>%  ggplot() +  aes(x=X$chflow, y = Y$current ) + geom_point() +
  ylab("Dividendo actuales") + xlab("Flujo de efectivo") 

p14 <- as.data.frame(Y[,2]) %>%  ggplot() +  aes(x=X$mktcap, y = Y$current ) + geom_point() +
  ylab("Dividendo futuro") + xlab("CapitalizaciÃ³n del mercado") 
p15 <- as.data.frame(Y[,2]) %>%  ggplot() +  aes(x=X$netcash, y = Y$current ) + geom_point() +
  ylab("Dividendo futuro") + xlab("Efectivo neto") 
p16 <- as.data.frame(Y[,2]) %>%  ggplot() +  aes(x=X$chflow, y = Y$current ) + geom_point() +
  ylab("Dividendo futuro") + xlab("Flujo de efectivo") 

grid.arrange(p11, p12, p13, p14, p15, p16, nrow = 2)
```

Son pocos datos, la distrribución entre respuesta y covariables se ven como en el gráfico de arriba.

A continuación presentamos el gráfico de correlación de las observaciones, las covariables tiene relación lineal negativa respecto a las respuestas.

```{r message=F}
# corplot
cbind(X,Y) %>% cor %>% corrplot.mixed()

```



```{r message=F}
# modelo
modelo2 <- lm(as.matrix(Y)~ X$mktcap + X$netcash + X$chflow)
summary(modelo2)
```
Corremos el modelo y en la primera respuesta que son los dividendos actuales, no se tiene signidicancia en los coeficientes  y un $R^2$ muy bajo.



```{r message=F}
i <- 1:2
sapply(i , function(i) shapiro.test(modelo2$residuals[,i]))
```

Probando  normalida en los residuales tenemos en forma separada existe normalidad solo para los residuales de la segunda respuesta.

Observamos que los residuales no esten correlacionados con el ajuste del modelo conjunto.

```{r message=F}
# supuestos del modelo e'yest

t(residuals)%*%yest %>% as.data.frame %>% kable %>% kable_styling
```

Que la suma de residuales sea cero.

```{r message=F}
# suma de residuales igual a cero
colMeans(residuals) %>% as.data.frame %>% kable %>% kable_styling
```

Ahora para contrastar lo anterior, la regresión multivariada, aplicamos la preuba MANOVA

```{r message=F}

res.man <- manova(as.matrix(Y)~ as.matrix(X))
summary.aov(res.man)

```
Observamos que solo en la primera respues, dividendos actuales, los factores no son significativos; sin embargo, para la segunda respuesta por lo son ligeramente.

Construimos los intervalos de confianza


```{r message=F}
intervalo <- round(confint(modelo2,level=0.95),3)
rownames(intervalo) <-c("rent:intercepto ","current:mktcap ", "current:netcash","current:chflow",
                        "payout:intercepto ","payout:mktcap ", "payout:netcash","payout:chflow")

intervalo %>% kable %>% kable_styling
```


Ahora le aplicamos logaritmo al modelo multivariado con el fin de ver la mejora.

```{r message=F}

X <- situacionFinanciera[c(2,3,4)] 
X <- sapply(i<-1:3, function(i) X[,i] <- as.numeric(gsub(",", "", X[,i])))
colnames(X) <- c("mktcap", "netcash","chflow")
X <- X %>% as.data.frame
X <- log(X)
```

Observamos gráficos para evaliar normalidad en la distribución de las variables

```{r message=F}
# Exploratorio de datos
p1 <- ggqqplot(X$mktcap) + theme_gray() +  labs(title="QQ-plot",
                                                subtitle = "log CapitalizaciÃ³n del mercado")
p3 <- ggqqplot(X$netcash) + theme_gray() +  labs(title="QQ-plot",
                                                 subtitle = "log Efectivo neto")
p5 <- ggqqplot(X$chflow) + theme_gray() +  labs(title="QQ-plot",
                                                subtitle = "log Flujo de efectivo")
grid.arrange(p1, p3, p5, nrow = 1)
```


```{r message=F}

p11 <- as.data.frame(Y[,1]) %>%  ggplot() +  aes(x=X$mktcap, y = Y$current ) + geom_point() +
  ylab("Dividendo actuales") + xlab("log CapitalizaciÃ³n del mercado") 
p12 <- as.data.frame(Y[,1]) %>%  ggplot() +  aes(x=X$netcash, y = Y$current ) + geom_point() +
  ylab("Dividendo actuales") + xlab("log Efectivo neto") 
p13 <- as.data.frame(Y[,1]) %>%  ggplot() +  aes(x=X$chflow, y = Y$current ) + geom_point() +
  ylab("Dividendo actuales") + xlab("log Flujo de efectivo") 

p14 <- as.data.frame(Y[,2]) %>%  ggplot() +  aes(x=X$mktcap, y = Y$current ) + geom_point() +
  ylab("Dividendo futuro") + xlab("log CapitalizaciÃ³n del mercado") 
p15 <- as.data.frame(Y[,2]) %>%  ggplot() +  aes(x=X$netcash, y = Y$current ) + geom_point() +
  ylab("Dividendo futuro") + xlab("log Efectivo neto") 
p16 <- as.data.frame(Y[,2]) %>%  ggplot() +  aes(x=X$chflow, y = Y$current ) + geom_point() +
  ylab("Dividendo futuro") + xlab("log Flujo de efectivo") 

grid.arrange(p11, p12, p13, p14, p15, p16, nrow = 2)
```

Realizamos el modelo con logaritmos. Nota: no se quitan outliers por que se tienen muy pocas observaciones.

```{r message=F}

# modelo
modelo2_log <- lm(as.matrix(Y)~ X$mktcap + X$netcash + X$chflow)
summary(modelo2_log)

```

El modelo de la respuesta 1, dividendos corrietes, no mejora, presenta coeficientes no significativos. En cambio, la respuesta 2, dividendos futuros, mejora notablemente, ocn coeficientes muy significatvos, pero no el efectivo neto. 
El mercado de capitales afecta deforma negativa al dividendo futuro, con camios de una unidad porcentual  afectaría en $-5.35360 $ los dividendos futuros, e incrementos de una unidad porcentual en los flujos de efectivo, implica un cabio en las unidades de los dividendos futuros de  $5.33105 $ aproximadamente. El valor del $R^2$ en el modelo individual mejora, pero en conjunto la primera respuesta no es adecuada.

```{r message=F}
# malo en coeficientes
i <- 1:2
sapply(i , function(i) shapiro.test(modelo2_log$residuals[,i]))
```

Se tiene que los residuales no son normales e base al tes de normalidad para los residuales seprados.

Se realiza análisis de varianza con MANOVA como segunda añternativa para identificar si los fatores son significativos para las respuestas.

```{r message=F}
res.man <- manova(as.matrix(Y)~ as.matrix(X))
summary.aov(res.man)
```

Vemos que el modelo con logaritmos en los factores solo es adecuado para la segunda respueta, pero no para la primera.

Construimos intervalose de confianza para el modelos en logaritmos.


```{r message=F}

intervalo <- round(confint(modelo2_log,level=0.95),3)
rownames(intervalo) <-c("rent:intercepto ","current:mktcap ", "current:netcash","current:chflow",
                        "payout:intercepto ","payout:mktcap ", "payout:netcash","payout:chflow")

intervalo %>% kable %>% kable_styling
```


Con el modelo en logaritomos lo  coeficientes para la respuesta de los dividendos actuales no eran significativos, y en todos los casos el flujo neto no presenta significancia en los modelos, esto se puede deber a multicolinealidad o que en realidad no explique nada en las respuestas.

Aplicamos la prueba de razón de verosimilitud bajo la hipótesis de $H_0:\beta_2=0$; esto es que el flujo neto explica a las respuestas en su conjunto.

```{r message=F}

# modelo completo
ones <- X$mktcap %>% length %>% diag %>% diag %>% as.matrix
Z <- X %>% as.matrix
Y <- Y %>% as.matrix
B <- solve(t(Z)%*%Z)%*%t(Z)%*%Y # etiquetas mal de columna
Yest <- Z%*%B
e <- Y - Yest
RSS <- t(e)%*%e

# modelo netcash=0
Z2 <- X[c(1,3)] %>% as.matrix
B2 <- solve(t(Z2)%*%Z2)%*%t(Z2)%*%Y
Yest2 <- Z2%*%B2
e2 <- Y - Yest2
RSS2 <- t(e2)%*%e2
# Wilks' lambda
H <-RSS2- RSS
E <- RSS
lambdaWilks <- det(E)/(det(E+H))

-2*log10(lambdaWilks)
m <- 2
r <- 3
n <- length(Y[,1])
q <- 2
Fcritico <- qf(.05, m*(r-q), n-r-m, lower.tail = F)
```

$$\Lambda=\frac{|E|}{|E+H|}= 0.9162667$$ 


$$F_{3,46}=4.102821$$ 

$$\Lambda \leq F_{3,46}$$
Podeos concluir que no se rechaza la hipótesis nula y, por lo tanto, el flujo neto no estaría presentando efecto en la respuestas "en conjunto".






**(b) También verifica el uso de otras variables explicativas basadas en funciones no lineales tales como la proporción entre el flujo de efectivo y la capitalización**

```{r message=F}
X <- situacionFinanciera[c(2,3,4)] 
X <- sapply(i<-1:3, function(i) X[,i] <- as.numeric(gsub(",", "", X[,i])))
X <- cbind(X, situacionFinanciera[c(5,6)] )
colnames(X) <- c("mktcap", "netcash","chflow","prflow", "prpcap" )
```

Vemos si existe multicolinealidad añadiendo a las covariables los porcentajesde capitalización y de flujos en efectivo.
```{r message=F}
# parece existir multicolinealidad
valoresPropios <- X %>% cor %>% eigen
val <- valoresPropios$values %>% as.data.frame
indice <- c(1:5)
val <- cbind(val,indice)
valorPlot <- val %>% ggplot() + aes(y=.,x=indice)+ geom_point() + geom_line() +
  labs(title="valores propios", x="# eigenvalues", y="valor propio")
ggplotly(valorPlot)

```

Detecta mucha colinealidad, esto debido a que los porcentajes se construyen con algunas covariables.
```{r message=F}
# Numero de condicion de la matriz
phi <- max(valoresPropios$values)/min(valoresPropios$values)
phi # mucha colinealidad en los datos
```



Se utilizan las variables de dinero en logaritmo, las de porcentaje no. Precentamos las variables de los porcentajes

```{r message=F}
# utilice las variables con log
X[c(1,2,3)] <- X[c(1,2,3)] %>% log

# Exploratorio de datos
p1 <- ggqqplot(X$prflow) + theme_gray() +  labs(title="QQ-plot",
                                                subtitle = "% flujo de efectivo")
p3 <- ggqqplot(X$prpcap) + theme_gray() +  labs(title="QQ-plot",
                                                 subtitle = "% capitalizaciÃ³n")

grid.arrange(p1, p3, nrow = 1)
```

Se observan colas pesada.

Vemos la dispersión de los porcentajers respecto a las varriables respuestas.

```{r message=F}

p11 <- as.data.frame(Y[,1]) %>%  ggplot() +  aes(x=X$prflow, y = Y[,1] ) + geom_point() +
  ylab("Dividendo actuales") + xlab("% flujo de efectivo") 
p12 <- as.data.frame(Y[,1]) %>%  ggplot() +  aes(x=X$prpcap, y = Y[,1] ) + geom_point() +
  ylab("Dividendo actuales") + xlab("% capitalizacn") 


p14 <- as.data.frame(Y[,2]) %>%  ggplot() +  aes(x=X$prflow, y = Y[,2] ) + geom_point() +
  ylab("Dividendo futuro") + xlab("% flujo de efectivo") 
p15 <- as.data.frame(Y[,2]) %>%  ggplot() +  aes(x=X$prpcap, y = Y[,2] ) + geom_point() +
  ylab("Dividendo futuro") + xlab("% capitalizacin") 

grid.arrange(p11, p12, p14, p15, nrow = 2)

```

Aplicamos el modelo que considera a todas las variables 

$$Y_i=Z_{ij}\beta_j$$
con $\beta$ que incluye al mercado de capitales, el flujo neto, el flujo de efectivo y, el porcentaje de flujo de efectivo y capitalización,
```{r message=F}

# modelo
modelo3_log <- lm(as.matrix(Y)~ X$mktcap + X$netcash + X$chflow + X$prflow + X$prpcap)
summary(modelo3_log)
```

Los ajustes en el modelo son malos, asimismo, se juega con varias combinaciones.

En este modelo solo utilizamos los porcentajes como covariables, ya que utilizar las otras presentan mayor colinealidad, ya que estos porcentajes se construyen con esas variables.

```{r message=F}
# mucha multicolinealidad probca es 
modelo3_log2 <- lm(as.matrix(Y)~  X$prflow + X$prpcap)
summary(modelo3_log2)
```

El modelo de la respuesta  uno no tiene coeficientes significativos e indica un mal ajuste. El modelo de la repsuesta dos, solocuenta con el porcentaje de flujos de efectivos como significativo, y con un $R^2$ alto.

En conclusión, las covariables mercado de capital, flujo de efectivo, el capital neto, porcentaje de flujo neto, y porcentaje de capitalización, no explican adecuadamente a los dividendo actuales y futuros, esto por la alta multicolinealidad entre las covariables, que hace que se afecten entre si, haciendo que no sean significativos. A su vez, realizar regresión con logaritmos y con respuestas separadas, puede que mejore un poco en la explicaciónd de algunas variables a cada repsuesta.

*Alternativas*
Podemos realizar PCA a la matriz de corralación de las observaciones, y utilizar las proyecciónes para construir una base ortogonal y tener covariables ortogonales, capaces de mejorar la explicación del modelo.


Utilizamos PCA con tres componentes ya que son los que explican aproximadamente el $80\%$ de la varianza.
```{r message=F}

valores <-  princomp(X, cor = T)
valores %>% summary
X_scores <- valores$scores
```

Realizamos el modelo con las proyeciones de la componete una y dos.
```{r message=F}
modelo3_scores <- lm(as.matrix(Y)~ X_scores[,1] + X_scores[,2] + X_scores[,3] )
summary(modelo3_scores)
```
Observamos que la respuesta uno tiene el intecepto significativos; no obstante, los coeficiendes de la componente uno y dos no los son, su ajuste no es el adecuado, pero esto ya se explica dado a que muchas de las observacioenes del dividendo actual tienen valores cero. Por otra parte la respuesta de los dividendos actuales mejora de forma significativa, con sus coeficientes significativos y una $R2$ ceracana a uno. 


Probamos normalidad en los residuales. Concluyendo que a maner aindividual los residuales son normales.
```{r message=F}
# malo en coeficientes
i <- 1:2
sapply(i , function(i) shapiro.test(modelo3_scores$residuals[,i]))

```

Contrastamos la regresión con MANOVA para ver si los factores en este modelo son sifnificativos.
```{r message=F}
res.man <- manova(as.matrix(Y)~ as.matrix(X_scores[,(1:3)]))
summary.aov(res.man)
```

Concluimos que los scores son significativos solo para la segunda respuesta pero no para el modelo en conjunto.



La dificultad en PCR, es la interpretación de los coeficientes, para esto realizamos la rotación de los coeficientes con el vector propio de los tres primeros componentes.

$$\beta_{ols}=V\beta{pcr}$$
```{r message=F}

beta <- modelo3_scores$coefficients
loadings <- valores$loadings[,(1:3)] %>% as.matrix
beta_originales <-loadings%*%beta[(2:4),]

beta_originales %>% kable %>% kable_styling
```

En conclusión los modelos presentan multicolinealidad en las covariables que hacen que el modelo se desempeñe mal, esto utilizando las series a niveles y en logaritmos. Por otro lado, las variable de los dividendos contiene muchos valores ceros, los cuales no se retiran por se pocas observaciones, y por se lo que reportan las compañias, pero generando problemas, lo que se puede hacer es una regresión al origen, pero afecta a la otra respuesta; es por eso que estas respuestas se modelarían meojor de forma separada. Por último, otra alternativa fue PCR, en cual trajó modelos mejores a los anteriores; no obstante los dividendos actuales caudan ruido en la regresión. 


